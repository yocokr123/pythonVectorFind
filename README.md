# 🧠 pythonVectorSearch - OpenSearch 임베딩 기반 문맥검색 시스템

이 프로젝트는 **OpenSearch**와 **Sentence Transformers**를 사용하여 임베딩 기반 문맥검색을 구현한 시스템입니다. 문서를 벡터로 변환하고 의미적 유사도를 기반으로 검색을 수행합니다.

## 📋 목차

- [프로젝트 소개](#프로젝트-소개)
- [주요 기능](#주요-기능)
- [설치 방법](#설치-방법)
- [사용 방법](#사용-방법)
- [프로젝트 구조](#프로젝트-구조)
- [파이썬 기초 설명](#파이썬-기초-설명)

## 🎯 프로젝트 소개

이 프로젝트는 다음과 같은 특징을 가지고 있습니다:

- **임베딩 기반 검색**: 문서와 쿼리를 벡터로 변환하여 의미적 유사도 계산
- **동의어 처리**: "AI"로 검색하면 "인공지능", "머신러닝" 등도 찾음
- **문맥 이해**: "웹 개발"로 검색하면 관련 기술들도 함께 찾음
- **하이브리드 검색**: 전통적인 키워드 검색과 문맥검색을 결합
- **가중치 조정**: 문맥검색과 키워드검색의 비율을 사용자가 설정 가능
- **최적의 결과**: 정확성과 관련성을 모두 고려한 검색 결과
- **다양한 검색 옵션**: 일반 검색, 태그 검색, 카테고리 필터링
- **사용자 친화적 인터페이스**: 명령줄 기반의 직관적인 메뉴 시스템
- **확장 가능한 구조**: 새로운 기능을 쉽게 추가할 수 있는 모듈화된 설계
- **REST API**: Java 등 다른 언어에서 호출 가능한 REST API 제공
- **실시간 임베딩**: 문서 추가 시 자동 임베딩 생성

## ✨ 주요 기능

### 🔍 문맥검색 (의미적 유사도)
- **임베딩 기반 검색**: 문서와 쿼리를 벡터로 변환하여 의미적 유사도 계산
- **동의어 처리**: "AI"로 검색하면 "인공지능", "머신러닝" 등도 찾음
- **문맥 이해**: "웹 개발"로 검색하면 관련 기술들도 함께 찾음

### 🎯 하이브리드 검색
- **키워드 + 문맥**: 전통적인 키워드 검색과 문맥검색을 결합
- **가중치 조정**: 문맥검색과 키워드검색의 비율을 사용자가 설정 가능
- **최적의 결과**: 정확성과 관련성을 모두 고려한 검색 결과

### 🏷️ 태그 검색
- **태그 기반 필터링**: 특정 태그가 포함된 문서만 검색
- **다중 태그 지원**: 여러 태그를 동시에 검색 가능

### 📊 카테고리 필터
- **카테고리별 검색**: 특정 카테고리의 문서만 검색
- **검색 범위 제한**: 더 정확하고 관련성 높은 결과 제공

## 🚀 기술 스택

- **OpenSearch**: 벡터 검색 엔진
- **Sentence Transformers**: 텍스트 임베딩 모델
- **Python**: 메인 프로그래밍 언어
- **NumPy**: 수치 계산
- **Pandas**: 데이터 처리

## 📋 시스템 요구사항

- Python 3.8 이상
- OpenSearch 2.0 이상
- 최소 4GB RAM (임베딩 모델 로드용)

## 🛠️ 설치 및 실행

### 1. 저장소 클론
```bash
git clone <repository-url>
cd pythonVectorSearch
```

### 2. 가상환경 생성 및 활성화
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. 의존성 설치
```bash
pip install -r requirements.txt
```

### 4. OpenSearch 실행
Docker를 사용하여 OpenSearch를 실행합니다:
```bash
docker run -d \
  --name opensearch \
  -p 9200:9200 \
  -p 9600:9600 \
  -e "discovery.type=single-node" \
  -e "plugins.security.disabled=true" \
  opensearchproject/opensearch:latest
```

### 5. 프로그램 실행
```bash
python main.py
```

## 🎮 사용 방법

### 프로그램 시작
프로그램을 실행하면 다음과 같은 메뉴가 표시됩니다:

```
🧠 임베딩 기반 문맥검색 메뉴
==================================================
1. 🔍 문맥검색 (의미적 유사도)
2. 🎯 하이브리드 검색 (키워드 + 문맥)
3. 🏷️  태그 검색
4. 📊 통계 보기
5. 📝 새 문서 추가
6. 🚪 종료
==================================================
```

### 1. 문맥검색 (의미적 유사도)
- **순수 임베딩 기반 검색**
- 의미적 유사도를 기반으로 결과 정렬
- 동의어와 문맥을 이해하여 검색

**예시**:
- 검색어: "AI" → "인공지능", "머신러닝", "딥러닝" 관련 문서들
- 검색어: "웹 개발" → "HTML", "CSS", "JavaScript", "React" 관련 문서들

### 2. 하이브리드 검색 (키워드 + 문맥)
- **키워드 검색과 문맥검색의 결합**
- 가중치를 조정하여 검색 방식 제어
- 정확성과 관련성을 모두 고려

**가중치 설정**:
- 문맥검색 가중치: 0.7 (의미적 유사도)
- 키워드검색 가중치: 0.3 (정확한 키워드 매칭)

### 3. 태그 검색
- 특정 태그가 포함된 문서 검색
- 여러 태그를 쉼표로 구분하여 입력

**예시**: `파이썬, 프로그래밍, 기초`

### 4. 통계 보기
- 총 문서 수
- 인덱스 크기
- 사용 중인 임베딩 모델 정보
- 벡터 차원 정보

### 5. 새 문서 추가
- 문서 ID, 제목, 내용 입력
- 카테고리와 태그 설정 (선택사항)
- 자동으로 임베딩 생성 및 저장

## 🔧 고급 설정

### 임베딩 모델 변경
`search_engine.py`에서 다른 임베딩 모델을 사용할 수 있습니다:

```python
# 더 정확한 모델 (더 큰 모델)
model_name = 'sentence-transformers/all-mpnet-base-v2'

# 더 빠른 모델 (더 작은 모델)
model_name = 'sentence-transformers/all-MiniLM-L6-v2'

search_engine = ContextualSearchEngine(model_name=model_name)
```

### 하이브리드 검색 가중치 조정
검색 시 가중치를 실시간으로 조정할 수 있습니다:
- 문맥검색 가중치: 0.0 ~ 1.0
- 키워드검색 가중치: 0.0 ~ 1.0

## 📊 성능 최적화

### 벡터 검색 최적화
- **HNSW 알고리즘**: 빠른 근사 최근접 이웃 검색
- **코사인 유사도**: 벡터 간 유사도 계산
- **인덱스 설정**: 검색 성능 최적화

### 메모리 사용량
- 임베딩 모델: 약 100MB
- 벡터 저장: 문서당 약 1KB
- 총 메모리: 문서 수에 따라 증가

## 🐛 문제 해결

### OpenSearch 연결 오류